# ğŸ¤– Offline RAG Chatbot (PDF/DOCX Q&A using Local Vector DB)

An **offline Retrieval-Augmented Generation (RAG)** chatbot powered by **Qdrant**, **Transformers**, and **Streamlit**. This app lets you ask natural language questions from a collection of **PDF** and **DOCX** files **without internet or APIs**. It uses **sentence embeddings**, performs semantic search on a **local vector database**, and returns matching document chunks.

---

## ğŸš€ Features

- ğŸ’¬ Ask questions across multiple documents
- ğŸ“„ Supports `.pdf` and `.docx`
- ğŸ” Displays source filename, page number, and chunk ID
- âš¡ Fast local search using [Qdrant](https://qdrant.tech/)
- âœ… Fully offline â€” no HuggingFace or OpenAI APIs
- ğŸ–¥ï¸ Simple Streamlit-based user interface

---

## ğŸ“ Folder Structure

rag_chatbot/
â”œâ”€â”€ app.py # Streamlit UI
â”œâ”€â”€ rag_chatbot.py # PDF/DOCX parsing & indexing
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # This file
â”œâ”€â”€ data/ # Raw input documents
â”‚ â”œâ”€â”€ file1.pdf
â”‚ â”œâ”€â”€ file2.docx
â”‚ â””â”€â”€ ...
â””â”€â”€ qdrant_storage/ # Local Qdrant vector DB (auto-created)


---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/rag_chatbot.git
cd rag_chatbot
2. Create a Virtual Environment
bash
Copy
Edit
python -m venv venv
venv\Scripts\activate  # Windows
3. Install Requirements
bash
Copy
Edit
pip install -r requirements.txt
4. Download & Start Qdrant (Local Vector DB)
Download the Qdrant Windows binary and extract it.

Then in CMD:

bash
Copy
Edit
cd path\to\qdrant-folder
qdrant.exe
This should run Qdrant on localhost:6333.

5. Index the Documents
Make sure your .pdf and .docx files are in the data/ folder. Then run:

bash
Copy
Edit
python rag_chatbot.py
This creates vector embeddings and stores them in Qdrant.

6. Launch the Chatbot UI
bash
Copy
Edit
streamlit run app.py
ğŸ’¡ Usage Guide
Ask a question in the text box.

The app retrieves top 3 relevant document chunks.

Each result includes:

âœ… The matching content

ğŸ“ Source file name

ğŸ“„ Page number

ğŸ§© Chunk ID

If no results are found, it will display â€œâŒ Not foundâ€.

ğŸ§  Architecture & Design
âœ… Document Parsing
.pdf files parsed using pdfplumber

.docx files parsed using python-docx

âœ… Chunking Strategy
Split each pageâ€™s text into logical chunks (~500 characters)

Each chunk is associated with:

filename

page number

chunk ID

raw text

âœ… Embedding & Retrieval
Sentence embeddings generated using:

r
Copy
Edit
all-MiniLM-L6-v2 (384-dim)
Embedded vectors are stored in Qdrant, a fast local vector DB

During query, the user input is also embedded and matched using cosine similarity

âš™ï¸ Hardware Used
Component	Spec
OS	Windows 11
CPU	Intel Core i5/i7
RAM	8 GB or higher
GPU	âŒ Not required
Storage	100 MB (Qdrant + Docs)
Internet	âŒ Not required

ğŸ“Œ Observations
Chunking by 500â€“800 characters balances context & precision

Qdrantâ€™s local performance is near-instant (<100ms)

all-MiniLM-L6-v2 gives excellent results with low resource usage

Works fully offline without calling APIs

Easy to scale: Just add more files in /data

ğŸ“ Example Questions
You can try:

â€œWhat are the features of the Techline IO interface?â€

â€œHow to configure the 1756 module?â€

â€œWhat does the LG document explain about safety?â€
ğŸ§³ How to Submit
Zip the folder:

python
Copy
Edit
rag_chatbot.zip
Push to GitHub:

Include .gitignore

Include README.md

Include requirements.txt

Include /data folder with documents (or sample files)

ğŸ”— Credits
Qdrant

Sentence Transformers

Streamlit

